{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6225ba-3765-4234-93ed-ca3f1d826359",
   "metadata": {},
   "source": [
    "# Naive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5db98-255b-4cc3-a6ac-e3cd49b2514d",
   "metadata": {},
   "source": [
    "# A RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118927c9",
   "metadata": {},
   "source": [
    "## Download Movies Dataset from Kaggle\n",
    "\n",
    "Follow these steps to download the dataset:\n",
    "\n",
    "1. **Get your Kaggle API credentials:**\n",
    "   - Go to https://www.kaggle.com/settings/account\n",
    "   - Scroll down to \"API\" section\n",
    "   - Click \"Create New Token\"\n",
    "   - This downloads a `kaggle.json` file\n",
    "\n",
    "2. **Upload the kaggle.json file** to this workspace or run the cell below to set it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859b9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==1.11.0 (from -r requirements.txt (line 1))\n",
      "  Using cached accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting chromadb==1.3.2 (from -r requirements.txt (line 2))\n",
      "  Using cached chromadb-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting datasets==4.4.1 (from -r requirements.txt (line 3))\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting kaggle==1.7.4.5 (from -r requirements.txt (line 4))\n",
      "  Using cached kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain==0.1.20 (from -r requirements.txt (line 5))\n",
      "  Using cached langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-community==0.0.38 (from -r requirements.txt (line 6))\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core==0.1.52 (from -r requirements.txt (line 7))\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters==0.0.2 (from -r requirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting lxml==6.0.2 (from -r requirements.txt (line 9))\n",
      "  Using cached lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting matplotlib==3.10.3 (from -r requirements.txt (line 10))\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib-inline==0.1.7 (from -r requirements.txt (line 11))\n",
      "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting nltk==3.9.2 (from -r requirements.txt (line 12))\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting numpy<2.0.0 (from -r requirements.txt (line 13))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 14))\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting safetensors==0.6.2 (from -r requirements.txt (line 15))\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting scikit-learn==1.7.0 (from -r requirements.txt (line 16))\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (0.13.2)\n",
      "Collecting sentence-transformers==5.1.2 (from -r requirements.txt (line 18))\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting sentencepiece==0.2.1 (from -r requirements.txt (line 19))\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting tiktoken==0.12.0 (from -r requirements.txt (line 20))\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==2.7.1 (from -r requirements.txt (line 21))\n",
      "  Using cached torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting transformers==4.57.1 (from -r requirements.txt (line 22))\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from accelerate==1.11.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate==1.11.0->-r requirements.txt (line 1)) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from accelerate==1.11.0->-r requirements.txt (line 1)) (6.0.3)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate==1.11.0->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pydantic>=1.9 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb==1.3.2->-r requirements.txt (line 2)) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm>=4.65.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb==1.3.2->-r requirements.txt (line 2)) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb==1.3.2->-r requirements.txt (line 2)) (4.25.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets==4.4.1->-r requirements.txt (line 3)) (3.19.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets==4.4.1->-r requirements.txt (line 3))\n",
      "  Using cached pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets==4.4.1->-r requirements.txt (line 3))\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/codespace/.local/lib/python3.12/site-packages (from datasets==4.4.1->-r requirements.txt (line 3)) (2.32.5)\n",
      "Collecting xxhash (from datasets==4.4.1->-r requirements.txt (line 3))\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets==4.4.1->-r requirements.txt (line 3))\n",
      "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1->-r requirements.txt (line 3)) (2025.9.0)\n",
      "Requirement already satisfied: bleach in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (3.11)\n",
      "Collecting protobuf (from kaggle==1.7.4.5->-r requirements.txt (line 4))\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle==1.7.4.5->-r requirements.txt (line 4))\n",
      "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle==1.7.4.5->-r requirements.txt (line 4))\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /home/codespace/.local/lib/python3.12/site-packages (from kaggle==1.7.4.5->-r requirements.txt (line 4)) (0.5.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Using cached sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.1.52->-r requirements.txt (line 7))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=20.0 (from accelerate==1.11.0->-r requirements.txt (line 1))\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 10)) (3.2.5)\n",
      "Requirement already satisfied: traitlets in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib-inline==0.1.7->-r requirements.txt (line 11)) (5.14.3)\n",
      "Collecting click (from nltk==3.9.2->-r requirements.txt (line 12))\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk==3.9.2->-r requirements.txt (line 12)) (1.5.2)\n",
      "Collecting regex>=2021.8.3 (from nltk==3.9.2->-r requirements.txt (line 12))\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 14)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 14)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn==1.7.0->-r requirements.txt (line 16)) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn==1.7.0->-r requirements.txt (line 16)) (3.6.0)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate==1.11.0->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 21)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 21)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 21)) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1->-r requirements.txt (line 21))\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5)) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==1.3.2->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==1.3.2->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.3.2->-r requirements.txt (line 2)) (0.16.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.21.0->accelerate==1.11.0->-r requirements.txt (line 1))\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.52->-r requirements.txt (line 7)) (3.0.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=1.9->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=1.9->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=1.9->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 5))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb==1.3.2->-r requirements.txt (line 2)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb==1.3.2->-r requirements.txt (line 2)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb==1.3.2->-r requirements.txt (line 2)) (0.28.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/codespace/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2)) (1.9.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle==1.7.4.5->-r requirements.txt (line 4))\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==1.3.2->-r requirements.txt (line 2)) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->-r requirements.txt (line 21)) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb==1.3.2->-r requirements.txt (line 2)) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.7.1->-r requirements.txt (line 21)) (3.0.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.3.2->-r requirements.txt (line 2))\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading chromadb-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=1d744575ef2c66c12d1cc6d23f7f7628adec02bfbdef05cfd1376c586bf6bbfb\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: text-unidecode, pypika, nvidia-cusparselt-cu12, flatbuffers, durationpy, zipp, xxhash, websockets, uvloop, urllib3, typing-inspection, triton, tqdm, tenacity, shellingham, sentencepiece, safetensors, regex, python-slugify, python-dotenv, pyproject_hooks, pydantic-core, pybase64, pyasn1, pyarrow, protobuf, propcache, packaging, overrides, orjson, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mypy-extensions, multidict, mmh3, mdurl, matplotlib-inline, lxml, jsonpatch, importlib-resources, humanfriendly, httptools, hf-xet, grpcio, greenlet, frozenlist, distro, dill, click, cachetools, bcrypt, backoff, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, typing-inspect, SQLAlchemy, rsa, pydantic, pyasn1-modules, pandas, opentelemetry-proto, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, multiprocess, marshmallow, markdown-it-py, importlib-metadata, googleapis-common-protos, coloredlogs, build, aiosignal, tiktoken, scikit-learn, rich, requests-toolbelt, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, nvidia-cusolver-cu12, matplotlib, kaggle, huggingface_hub, google-auth, dataclasses-json, aiohttp, typer, torch, tokenizers, opentelemetry-semantic-conventions, langsmith, kubernetes, transformers, opentelemetry-sdk, langchain-core, datasets, accelerate, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-community, langchain, chromadb\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [uvloop]t-cu12]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [uvloop]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [uvloop]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  8/118\u001b[0m [uvloop]\n",
      "\u001b[2K  Attempting uninstall: packaging0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [protobuf]spection]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: numpym╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [nvidia-cublas-cu12]u12]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 39/118\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling numpy-2.3.4:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]las-cu12]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.4━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: matplotlib-inline━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: matplotlib-inline 0.2.1━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling matplotlib-inline-0.2.1:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-inline-0.2.1━━━━━━━━\u001b[0m \u001b[32m 40/118\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/118\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [pandas]les]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 71/118\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.2━━━━━━━━━━━\u001b[0m \u001b[32m 81/118\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m 86/118\u001b[0m [scikit-learn]-protos]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.290m━━━━━━━━━━\u001b[0m \u001b[32m 86/118\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: matplotlib━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.7[90m━━━━━━━━\u001b[0m \u001b[32m 94/118\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.7:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 95/118\u001b[0m [matplotlib]-cu12]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.7m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 95/118\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [aiohttp]uth]hub]\n",
      "\u001b[2K    Found existing installation: torch 2.9.0+cpu[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m100/118\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling torch-2.9.0+cpu:━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.9.0+cpu\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m102/118\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118/118\u001b[0m [chromadb]chromadb]]angchain-community]s]ions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.44 accelerate-1.11.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.2 chromadb-1.3.2 click-8.3.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 datasets-4.4.1 dill-0.4.0 distro-1.9.0 durationpy-0.10 flatbuffers-25.9.23 frozenlist-1.8.0 google-auth-2.43.0 googleapis-common-protos-1.72.0 greenlet-3.2.4 grpcio-1.76.0 hf-xet-1.2.0 httptools-0.7.1 huggingface_hub-0.36.0 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jsonpatch-1.33 kaggle-1.7.4.5 kubernetes-34.1.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.147 lxml-6.0.2 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-3.10.3 matplotlib-inline-0.1.7 mdurl-0.1.2 mmh3-5.2.0 multidict-6.7.0 multiprocess-0.70.18 mypy-extensions-1.1.0 nltk-3.9.2 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 orjson-3.11.4 overrides-7.7.0 packaging-23.2 pandas-2.2.3 posthog-5.4.0 propcache-0.4.1 protobuf-6.33.1 pyarrow-22.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.12.4 pydantic-core-2.41.5 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.2.1 python-slugify-8.0.4 regex-2025.11.3 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.2.0 rsa-4.9.1 safetensors-0.6.2 scikit-learn-1.7.0 sentence-transformers-5.1.2 sentencepiece-0.2.1 shellingham-1.5.4 tenacity-8.5.0 text-unidecode-1.3 tiktoken-0.12.0 tokenizers-0.22.1 torch-2.7.1 tqdm-4.67.1 transformers-4.57.1 triton-3.3.1 typer-0.20.0 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.3.0 uvicorn-0.38.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b54a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "# Option 1: Upload kaggle.json manually, then run:\n",
    "!mkdir -p ~/.kaggle\n",
    "# If you uploaded kaggle.json to the workspace root:\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f650b5",
   "metadata": {},
   "source": [
    "### Download Movies Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7622b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading the-movies-dataset.zip to /workspaces/Modern-AI-Agents/chr5\n",
      " 53%|█████████████████████▏                  | 121M/228M [00:00<00:00, 1.27GB/s]\n",
      "100%|████████████████████████████████████████| 228M/228M [00:00<00:00, 1.26GB/s]\n",
      "Archive:  the-movies-dataset.zip\n",
      "  inflating: credits.csv             \n",
      "  inflating: keywords.csv            \n",
      "  inflating: links.csv               \n",
      "  inflating: links_small.csv         \n",
      "  inflating: movies_metadata.csv     \n",
      "  inflating: ratings.csv             \n",
      "  inflating: ratings_small.csv       \n",
      "-rw-r--r-- 1 codespace codespace 182M Sep 21  2019 credits.csv\n",
      "-rw-r--r-- 1 codespace codespace 6.0M Sep 21  2019 keywords.csv\n",
      "-rw-r--r-- 1 codespace codespace 966K Sep 21  2019 links.csv\n",
      "-rw-r--r-- 1 codespace codespace 180K Sep 21  2019 links_small.csv\n",
      "-rw-r--r-- 1 codespace codespace  33M Sep 21  2019 movies_metadata.csv\n",
      "-rw-r--r-- 1 codespace codespace 677M Sep 21  2019 ratings.csv\n",
      "-rw-r--r-- 1 codespace codespace 2.4M Sep 21  2019 ratings_small.csv\n",
      "\n",
      "✅ Dataset downloaded and extracted!\n"
     ]
    }
   ],
   "source": [
    "# Download the Movies Dataset from Kaggle\n",
    "!kaggle datasets download -d rounakbanik/the-movies-dataset\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip -o the-movies-dataset.zip\n",
    "\n",
    "# List the files\n",
    "!ls -lh *.csv\n",
    "\n",
    "print(\"\\n✅ Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20be8311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31023/1841053763.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('movies_metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movies_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693109f0-758d-408a-8cea-76ca97b3a4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NLTK data downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "print(\"✅ NLTK data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a06b0a",
   "metadata": {},
   "source": [
    "# Create VectorStore using CromeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee993629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "import chromadb\n",
    "\n",
    "df = df.loc[:5000,['original_title', 'overview']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca5968",
   "metadata": {},
   "source": [
    "## Step 1: Chunk the Overview Column using NLTKTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34510e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=1500)\n",
    "\n",
    "def split_overview(overview):\n",
    "    if pd.isna(overview):\n",
    "        return []\n",
    "    return text_splitter.split_text(str(overview))\n",
    "\n",
    "df['chunks'] = df['overview'].apply(split_overview)\n",
    "\n",
    "# Flatten the dataframe for easier processing\n",
    "chunked_df = df.explode('chunks').reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788098e",
   "metadata": {},
   "source": [
    "## Step 2: Embed with a SentenceTransformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae56ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')  # You can choose another model\n",
    "\n",
    "# Make sure all chunks are strings and not empty\n",
    "def encode_chunk(chunk):\n",
    "    if not isinstance(chunk, str) or chunk.strip() == \"\":\n",
    "        return None\n",
    "    return embedder.encode(chunk).tolist()\n",
    "\n",
    "chunked_df['embeddings'] = chunked_df['chunks'].apply(encode_chunk)\n",
    "\n",
    "# Drop rows where 'embeddings' is None\n",
    "chunked_df.dropna(subset=['embeddings'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703f78c",
   "metadata": {},
   "source": [
    "## Step 3: Store in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f15911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully stored in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize ChromaDB client and collection\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name='movies')\n",
    "\n",
    "# Insert data into ChromaDB\n",
    "for idx, row in chunked_df.iterrows():\n",
    "    collection.add(\n",
    "        ids=[str(idx)],\n",
    "        embeddings=[row['embeddings']],\n",
    "        metadatas=[{\n",
    "            'original_title': row['original_title'],\n",
    "            'chunk': row['chunks']\n",
    "        }]\n",
    "    )\n",
    "\n",
    "print(\"Data successfully stored in ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9b660c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [00:39<00:00, 19.57s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:18<00:00, 69.43s/it] \n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from chromadb import Client\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import torch\n",
    "\n",
    "# Load the SentenceTransformer model for encoding queries\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use the same model as for embedding documents\n",
    "\n",
    "# Load the text generation model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    device_map='auto' # load it in the current GPU\n",
    ")\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=800\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a5bba",
   "metadata": {},
   "source": [
    "## Function to retrieve top_k documents from ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c89cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_documents(query, collection, top_k=5):\n",
    "    # Embed the query using the SentenceTransformer model\n",
    "    query_embedding = sentence_model.encode(query).tolist()\n",
    "    \n",
    "    # Search for top_k similar documents in the collection\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    if not results['documents']:\n",
    "        print(\"No results found for the query.\")\n",
    "        return [], []\n",
    "    \n",
    "    # Extract chunks and titles from the results\n",
    "    chunks = []\n",
    "    titles = []\n",
    "    for document in results['metadatas'][0]:\n",
    "        chunks.append(document['chunk'])\n",
    "        titles.append(document['original_title'])\n",
    "    \n",
    "    return chunks, titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387e561",
   "metadata": {},
   "source": [
    "## Function to generate answer based on retrieved chunks and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1682df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer(query, chunks, titles, text_generation_pipeline):\n",
    "    # Prepare the context from chunks and titles\n",
    "    context = \"\\n\\n\".join([f\"Title: {title}\\nChunk: {chunk}\" for title, chunk in zip(titles, chunks)])\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"[INST]\n",
    "    Instruction: You're an expert in movie suggestions. Your task is to analyze carefully the context and come up with an exhaustive answer to the following question:\n",
    "    {query}\n",
    "    \n",
    "    Here is the context to help you:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    [/INST]\"\"\"\n",
    "    \n",
    "    # Generate the answer using the model\n",
    "    generated_text = text_generation_pipeline(prompt)[0]['generated_text']\n",
    "    \n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f31232",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "897365f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunks: ['Get swept up in the action as an armored car driver (Christian Slater) tries to elude a gang of thieves (led by Morgan Freeman) while a flood ravages the countryside.\\n\\nHard Rain is \"a wild, thrilling, chilling action ride\" filled with close calls, uncertain loyalties and heart-stopping heroics.', 'The film talks about a family that weathers all sorts of disasters and keeps going in spite of it all.\\n\\nIt is noted for its wonderful assortment of oddball characters.', 'Romantic comedy about aspiring writers in NY.', 'A comedy about families, the elements that bind them together, and about hope in the face of hardship.', \"Following on the heels of popular teen-scream horror movies, with uproarious comedy and biting satire.\\n\\nMarlon and Shawn Wayans, Shannon Elizabeth and Carmen Electra pitch in to skewer some of Hollywood's biggest blockbusters, including Scream, I Know What You Did Last Summer, The Matrix, American Pie and The Blair Witch Project.\"]\n",
      "Retrieved Titles: ['Hard Rain', 'The Hotel New Hampshire', 'Broadway Damage', 'Better Living', 'Scary Movie']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = chromadb.Client()\n",
    "# Use get_or_create_collection to avoid errors if collection doesn't exist\n",
    "#collection = client.get_or_create_collection(name='movies')\n",
    "\n",
    "query = \"What are some good movies to watch on a rainy day?\"\n",
    "top_k = 5\n",
    "\n",
    "# Retrieve documents\n",
    "chunks, titles = retrieve_documents(query, collection, top_k)\n",
    "print(f\"Retrieved Chunks: {chunks}\")\n",
    "print(f\"Retrieved Titles: {titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6926526",
   "metadata": {},
   "source": [
    "## Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1163e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "    Instruction: You're an expert in movie suggestions. Your task is to analyze carefully the context and come up with an exhaustive answer to the following question:\n",
      "    What are some good movies to watch on a rainy day?\n",
      "\n",
      "    Here is the context to help you:\n",
      "\n",
      "    Title: Hard Rain\n",
      "Chunk: Get swept up in the action as an armored car driver (Christian Slater) tries to elude a gang of thieves (led by Morgan Freeman) while a flood ravages the countryside.\n",
      "\n",
      "Hard Rain is \"a wild, thrilling, chilling action ride\" filled with close calls, uncertain loyalties and heart-stopping heroics.\n",
      "\n",
      "Title: The Hotel New Hampshire\n",
      "Chunk: The film talks about a family that weathers all sorts of disasters and keeps going in spite of it all.\n",
      "\n",
      "It is noted for its wonderful assortment of oddball characters.\n",
      "\n",
      "Title: Broadway Damage\n",
      "Chunk: Romantic comedy about aspiring writers in NY.\n",
      "\n",
      "Title: Better Living\n",
      "Chunk: A comedy about families, the elements that bind them together, and about hope in the face of hardship.\n",
      "\n",
      "Title: Scary Movie\n",
      "Chunk: Following on the heels of popular teen-scream horror movies, with uproarious comedy and biting satire.\n",
      "\n",
      "Marlon and Shawn Wayans, Shannon Elizabeth and Carmen Electra pitch in to skewer some of Hollywood's biggest blockbusters, including Scream, I Know What You Did Last Summer, The Matrix, American Pie and The Blair Witch Project.\n",
      "\n",
      "    [/INST] Based on these movie suggestions, here are some good movies to watch on a rainy day:\n",
      "\n",
      "1. Hard Rain - This action-packed film is perfect for a rainy day. It has an intense storyline, thrilling action scenes, and a great cast.\n",
      "\n",
      "2. The Hotel New Hampshire - If you're looking for a heartwarming and funny movie, this one is a great pick. It has a unique assortment of oddball characters, and is sure to keep you entertained.\n",
      "\n",
      "3. Broadway Damage - If you're in the mood for a romantic comedy, this is a great option. It's set in NY and follows the story of aspiring writers, making it relatable and entertaining.\n",
      "\n",
      "4. Better Living - This family-oriented comedy is perfect for a rainy day. It deals with themes of hope and resilience, making it both heartwarming and inspiring.\n",
      "\n",
      "5. Scary Movie - If you're looking for something lighthearted and funny, this spoof movie is a great pick. It skewers some of Hollywood's biggest blockbusters, making it a fun and entertaining way to spend a rainy day.\n"
     ]
    }
   ],
   "source": [
    "# Generate answer\n",
    "if chunks and titles:\n",
    "    answer = generate_answer(query, chunks, titles, text_generation_pipeline)\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"No relevant documents found to generate an answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19db7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c927b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
